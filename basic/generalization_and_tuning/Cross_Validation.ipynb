{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📂 Cross Validation（交叉验证）\n",
        "\n",
        "---\n",
        "\n",
        "## 📘 介绍\n",
        "\n",
        "在机器学习中，我们的最终目标是构建一个**泛化能力强**的模型，即在未见数据上也能保持良好性能。  \n",
        "但如果我们只是简单将数据划分为训练集 / 测试集一次评估，就容易受到：\n",
        "\n",
        "- 数据划分的**随机性影响**（比如刚好测试集中是噪声点）\n",
        "- 模型对某些数据划分**过拟合**或**欠拟合**\n",
        "- 评估结果**波动大，不可靠**\n",
        "\n",
        "为了解决这个问题，引入了 **交叉验证（Cross Validation）**：  \n",
        "> 将数据多次切分、循环训练与验证，最终对性能进行平均评估，从而更稳定、更可靠地估计模型的泛化能力。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 和 Holdout 的区别\n",
        "\n",
        "| 方法         | 特点                                               |\n",
        "|--------------|----------------------------------------------------|\n",
        "| Holdout      | 数据一次划分为训练集和验证集，快速但受随机影响大      |\n",
        "| Cross Validation | 多次划分、多轮验证，**更稳定，更能代表模型真实性能** |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 交叉验证常用于：\n",
        "\n",
        "- 模型选择与比较（哪种模型更稳定？）\n",
        "- 参数调优（GridSearchCV / RandomizedSearchCV）\n",
        "- 特征工程阶段评估新特征是否有效\n",
        "- 控制过拟合，判断模型是否泛化过强或过弱\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 常见交叉验证方法概览\n",
        "\n",
        "| 方法名                 | 适用场景               |\n",
        "|------------------------|------------------------|\n",
        "| K-Fold                 | 通用、高频、回归 / 分类任务       |\n",
        "| Stratified K-Fold      | 样本不均衡分类任务             |\n",
        "| Leave-One-Out (LOOCV)  | 样本少、无偏估计               |\n",
        "| Group K-Fold           | 分组样本，不能泄露组内信息        |\n",
        "| Time Series Split      | 时间序列预测任务，保留时间顺序     |\n",
        "\n"
      ],
      "metadata": {
        "id": "qmqLdHaXesYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔹 Train/Test Split（Holdout）\n",
        "\n",
        "---\n",
        "\n",
        "### 📘 方法介绍\n",
        "\n",
        "Train/Test Split（也称 Holdout 法）是最基础的验证方法：\n",
        "\n",
        "> 将原始数据集一次性划分为训练集（train set）与测试集（test set），然后在训练集上训练模型，在测试集上评估模型性能。\n",
        "\n",
        "常见划分比例：\n",
        "- 回归任务：80% 训练 / 20% 测试\n",
        "- 小样本场景：70/30、甚至 60/40 也常见\n",
        "\n",
        "---\n",
        "\n",
        "### 📐 示例流程\n",
        "\n",
        "```text\n",
        "原始数据集（1000 个样本）\n",
        "→ 训练集（800）用于拟合模型\n",
        "→ 测试集（200）用于评估泛化能力\n"
      ],
      "metadata": {
        "id": "sSIas0pAgsA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut"
      ],
      "metadata": {
        "id": "vOFAD33khc4x"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C5ikSAyeAbd",
        "outputId": "96665d5b-5cd0-44cb-9fbd-6bd8e4dc7a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始数据集大小: (20640, 8)\n",
            "训练集大小: (16512, 8)\n",
            "测试集大小: (4128, 8)\n"
          ]
        }
      ],
      "source": [
        "# 加载数据\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# 打印原始数据形状\n",
        "print(\"原始数据集大小:\", X.shape)\n",
        "\n",
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 打印划分后形状\n",
        "print(\"训练集大小:\", X_train.shape)\n",
        "print(\"测试集大小:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔁 K-Fold Cross Validation（K折交叉验证）\n",
        "\n",
        "---\n",
        "\n",
        "### 📘 介绍\n",
        "\n",
        "K-Fold 是最常用的一种交叉验证方法。\n",
        "\n",
        "> 将数据集划分为 K 个等份（folds），每次选取一个 fold 作为验证集，其余 K-1 个 fold 作为训练集。重复 K 次，最终将 K 次评估结果求平均，作为模型的最终性能表现。\n",
        "\n",
        "---\n",
        "\n",
        "### ⚙️ 原理\n",
        "\n",
        "- 将整个数据集平均分为 K 份\n",
        "- 执行 K 次训练-验证：\n",
        "  - 每次留出一份做验证集\n",
        "  - 其余 K-1 份用于训练\n",
        "- 最后对 K 次模型评估结果取平均，作为整体性能评估\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 特性\n",
        "\n",
        "- 每个样本都有一次成为验证集的机会\n",
        "- 更可靠、更稳定地估计模型泛化能力\n",
        "- 充分利用数据，提高训练效果\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 优点\n",
        "\n",
        "- 评估结果更稳定，减少因数据划分带来的波动\n",
        "- 每个样本都参与训练和验证，数据利用率高\n",
        "- 与模型无关，通用于所有监督学习算法\n",
        "\n",
        "---\n",
        "\n",
        "### ⚠️ 缺点\n",
        "\n",
        "- 需要训练 K 次模型，计算开销比一次划分大\n",
        "- 样本不均衡时可能出现验证集类别分布失衡\n",
        "  - → 可以使用 StratifiedKFold 保证分布一致\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 常用于\n",
        "\n",
        "- 模型选择、调参（GridSearchCV, RandomSearch）\n",
        "- 模型验证阶段的准确性评估\n",
        "- 样本量中等的泛化性能分析\n",
        "\n",
        "---\n",
        "\n",
        "### 💬 面试常见问题（含答案）\n",
        "\n",
        "1. **什么是 K-Fold？**\n",
        "   - 一种交叉验证方法，将数据划分为 K 份，每次取其中一份做验证，其余为训练，最后平均评估结果。\n",
        "\n",
        "2. **K-Fold 比 Train/Test Split 好在哪？**\n",
        "   - 更稳定，评估不依赖于一次划分的随机性；每个样本都被用来训练与验证。\n",
        "\n",
        "3. **K 取多少比较合适？**\n",
        "   - 通常取 5 或 10；样本少时可以更大，样本多时可以取 3~5 降低计算成本。\n",
        "\n",
        "4. **K-Fold 会不会泄露数据？**\n",
        "   - 若划分后才进行数据预处理（如归一化）即可避免泄露；错误顺序可能导致信息泄露。\n",
        "\n",
        "5. **它和 LOOCV 有什么区别？**\n",
        "   - LOOCV 是极限情况的 K-Fold（K=n），方差更高，计算代价也更大。\n",
        "\n"
      ],
      "metadata": {
        "id": "BT191IhhjFQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# 加载真实数据\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# 初始化 KFold（10折）\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# 显示每折划分的样本数量\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    print(f\"Fold {fold + 1}:\")\n",
        "    print(f\"  训练集大小: {len(train_index)}\")\n",
        "    print(f\"  验证集大小: {len(test_index)}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApDB8NZMhaUl",
        "outputId": "3a7bb195-3b95-4ac5-8faf-5f80a0ecee26"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 2:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 3:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 4:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 5:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 6:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 7:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 8:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 9:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n",
            "Fold 10:\n",
            "  训练集大小: 18576\n",
            "  验证集大小: 2064\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧬 Leave-One-Out Cross Validation（LOOCV）\n",
        "\n",
        "---\n",
        "\n",
        "### 📘 介绍\n",
        "\n",
        "LOOCV 是 K-Fold 的一个极端形式：\n",
        "\n",
        "> 每次只留出一个样本作为验证集，其余所有样本都用于训练。共进行 $n$ 次训练验证（$n$ 是样本数），每次验证一个样本，最后对所有结果取平均。\n",
        "\n",
        "---\n",
        "\n",
        "### ⚙️ 原理\n",
        "\n",
        "- 将整个数据集划分为 $n$ 个子集（每个子集只包含一个样本）\n",
        "- 每次从中选择一个样本作为验证集，其余 $n-1$ 个样本训练模型\n",
        "- 对所有 $n$ 次评估结果取平均，作为模型性能表现\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 特性\n",
        "\n",
        "- 每个样本都被严格地用于验证一次\n",
        "- 训练集最大化，每次只少一个样本\n",
        "- 非常适合样本数量极少的任务\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 优点\n",
        "\n",
        "- 几乎使用了所有数据做训练，数据利用率极高  \n",
        "- 验证评估无偏性强（每个样本被独立评估）  \n",
        "- 理论分析精确，适合统计建模\n",
        "\n",
        "---\n",
        "\n",
        "### ⚠️ 缺点\n",
        "\n",
        "- **训练次数 = 样本数** → 计算成本极高  \n",
        "- 每次验证只有 1 个样本 → 评估波动大（高方差）  \n",
        "- 不适用于大样本数据或计算资源有限场景\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 常用于\n",
        "\n",
        "- 医学 / 生物 / 金融等样本量极少领域\n",
        "- 理论分析场景（如置信区间估计、无偏估计）\n",
        "- 学术研究中的模型比较\n",
        "\n",
        "---\n",
        "\n",
        "### 💬 面试常见问题（含答案）\n",
        "\n",
        "1. **LOOCV 是什么？**\n",
        "   - Leave-One-Out 是每次用一个样本作为验证，其他样本用于训练的交叉验证方式。\n",
        "\n",
        "2. **优缺点分别是什么？**\n",
        "   - 优点：数据利用率极高、每个样本都被评估  \n",
        "   - 缺点：训练开销大、评估结果波动大\n",
        "\n",
        "3. **实际中你用过 LOOCV 吗？**\n",
        "   - 在小样本任务或做 baseline 验证时会尝试，实际工业任务中更倾向使用 KFold。\n",
        "\n",
        "4. **KFold 和 LOOCV 怎么选？**\n",
        "   - 样本少 → LOOCV 更优；样本多或需效率 → KFold 更可取\n",
        "\n",
        "5. **LOOCV 是否存在数据泄露风险？**\n",
        "   - 只要在划分后进行数据预处理，就不会泄露（如标准化应在每轮内部处理）\n",
        "\n"
      ],
      "metadata": {
        "id": "ww7BAFsDjiuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# 加载数据\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "\n",
        "# 初始化 LOOCV\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "# 打印前 3 折的划分信息（数据量大，避免全部打印）\n",
        "for i, (train_index, test_index) in enumerate(loo.split(X)):\n",
        "    print(f\"LOOCV 第 {i + 1} 折:\")\n",
        "    print(f\"  训练集大小: {len(train_index)}\")\n",
        "    print(f\"  验证集索引: {test_index}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    if i == 2:  # 只展示前 3 折\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94wXnoikjlt7",
        "outputId": "8ccfedcb-a734-4ba9-a9fd-066966908a9a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOOCV 第 1 折:\n",
            "  训练集大小: 20639\n",
            "  验证集索引: [0]\n",
            "------------------------------\n",
            "LOOCV 第 2 折:\n",
            "  训练集大小: 20639\n",
            "  验证集索引: [1]\n",
            "------------------------------\n",
            "LOOCV 第 3 折:\n",
            "  训练集大小: 20639\n",
            "  验证集索引: [2]\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}