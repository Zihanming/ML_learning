{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 什么是卷积神经网络（CNN）？\n",
        "\n",
        "卷积神经网络（Convolutional Neural Network, CNN）是一类专门处理**具有网格结构数据（如图像）**的神经网络。\n",
        "最典型的应用就是处理二维图像（二维像素网格）。相比传统的全连接神经网络（如 MLP），CNN 具有以下优势：\n",
        "\n",
        "#### ✅ CNN 的三大核心思想：\n",
        "1. **局部感受野（Local Receptive Field）**：每个神经元只处理输入的一小部分区域\n",
        "2. **权重共享（Weight Sharing）**：同一个卷积核在整个图像中滑动，参数复用，减少训练参数\n",
        "3. **下采样（Subsampling / Pooling）**：通过池化降低特征维度，提高模型对位置偏移的鲁棒性\n",
        "\n",
        "---\n",
        "\n",
        "#### 📷 图像数据的特性\n",
        "- 通常输入为形如 $ (C, H, W) $ 的三维张量（通道数、高度、宽度）\n",
        "  - 灰度图像：$1 \\times 28 \\times 28$\n",
        "  - 彩色图像：$3 \\times 224 \\times 224$\n",
        "\n",
        "CNN 能利用图像的空间结构，而不像 MLP 那样直接拉平成向量处理。\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔁 CNN 的常见结构组成：\n",
        "1. 卷积层（`Conv2D`）：提取局部空间特征\n",
        "2. 激活函数（ReLU）：增加非线性表达\n",
        "3. 池化层（`MaxPool2D`）：降低空间分辨率、减少参数\n",
        "4. 全连接层（`Linear`）：用于最终分类/回归\n",
        "\n",
        "一个典型 CNN 的结构如下：\n",
        "```text\n",
        "[输入图像] → [Conv → ReLU → Pool]*N → Flatten → Linear → 输出类别\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结一句话：\n",
        "> CNN 是专为图像/空间数据设计的高效神经网络，利用局部连接与共享参数，在参数数量更少的前提下能有效提取图像特征。"
      ],
      "metadata": {
        "id": "AqmMr5l768r6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2：卷积层（含核、填充、步幅解释）\n",
        "\n",
        "卷积层（`nn.Conv2d`）是 CNN 的核心构件，负责对图像进行“滑动窗口”式的特征提取。\n",
        "\n",
        "#### 🧮 卷积的主要参数：\n",
        "| 参数名       | 含义 |\n",
        "|--------------|------|\n",
        "| kernel_size  | 卷积核尺寸（如 3 表示 3×3）|\n",
        "| stride       | 卷积核滑动的步长（默认1） |\n",
        "| padding      | 输入周围补0的圈数（避免尺寸过快缩小）|\n",
        "| dilation     | 卷积核元素之间的间隔（控制感受野）|\n",
        "\n",
        "#### 📐 输出尺寸计算公式：\n",
        "给定输入尺寸 $W$、核大小 $F$、填充 $P$、步幅 $S$：\n",
        "$[ \\text{Output} = \\left\\lfloor \\frac{W - F + 2P}{S} \\right\\rfloor + 1 $]\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔍 示例\n",
        "- 输入图像：$1 \\times 28 \\times 28$\n",
        "- 卷积核大小：3×3，stride=1，padding=1\n",
        "- 输出大小：保持为 $28 \\times 28$\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧪 PyTorch 示例代码\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
        "x = torch.randn(1, 1, 28, 28)  # batch_size=1, channel=1, height=28, width=28\n",
        "out = conv(x)\n",
        "print(out.shape)  # torch.Size([1, 1, 28, 28])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 总结：\n",
        "> 卷积层通过可学习的卷积核滑动提取图像局部模式，是 CNN 提取空间特征的核心结构。\n"
      ],
      "metadata": {
        "id": "OwyOSUlM7qUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 模块 3：多输入通道与多输出通道\n",
        "\n",
        "在实际图像中，每张图片可能有多个通道（如 RGB 图像有 R/G/B 三个通道），而一个卷积层通常也会生成多个输出特征图（称为输出通道）。\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 多输入通道（Multiple Input Channels）\n",
        "- 卷积核的每个“通道”部分与对应输入通道相乘\n",
        "- 然后再将所有通道的结果相加：\n",
        "\n",
        "$$\n",
        "Y = \\sum_{i=1}^{C_{\\text{in}}} X^{(i)} * K^{(i)}\n",
        "$$\n",
        "\n",
        "其中：\n",
        "- $X^{(i)}$ 是第 $i$ 个输入通道\n",
        "- $K^{(i)}$ 是卷积核在该通道上的权重\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 多输出通道（Multiple Output Channels）\n",
        "- 一个卷积层可以设置多个输出通道（out_channels）\n",
        "- 每个输出通道都有独立的一组卷积核权重 → 提取不同类型的特征（如边缘、纹理、角点等）\n",
        "\n",
        "---\n",
        "\n",
        "#### 📊 PyTorch 示例代码\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 输入：batch_size=1, 输入通道=3（如RGB图像）, 高28宽28\n",
        "x = torch.randn(1, 3, 28, 28)\n",
        "\n",
        "# 卷积层：3输入通道，输出5个特征图（5个卷积核）\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, padding=1)\n",
        "out = conv(x)\n",
        "print(out.shape)  # torch.Size([1, 5, 28, 28])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结一句话：\n",
        "> 多输入通道允许模型融合来自不同维度的感知，多输出通道提供了对不同特征的并行检测，是 CNN 表达能力的重要来源。\n"
      ],
      "metadata": {
        "id": "Tzqh6vkZ8Hn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 模块 4：池化层（最大池化、平均池化）\n",
        "\n",
        "池化层（Pooling）用于在不增加参数的情况下，**减少特征图的空间尺寸**，从而降低计算量、减少过拟合，并增强模型对位置变化的鲁棒性。\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 常见池化操作：\n",
        "| 操作类型     | 含义与作用 |\n",
        "|--------------|------------|\n",
        "| 最大池化 MaxPool | 提取局部窗口中最大值，突出显著特征 |\n",
        "| 平均池化 AvgPool | 计算局部平均，保留整体趋势 |\n",
        "\n",
        "---\n",
        "\n",
        "#### 📐 尺寸计算公式：\n",
        "与卷积类似，池化层也有 kernel、stride、padding 等参数。\n",
        "若输入尺寸为 $W$，池化核大小为 $F$，步幅 $S$，填充为 $P$：\n",
        "$$\n",
        "\\text{Output} = \\left\\lfloor \\frac{W - F + 2P}{S} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔍 示例（2×2 最大池化）\n",
        "- 输入特征图尺寸：$1 \\times 28 \\times 28$\n",
        "- 使用 $2 \\times 2$ 池化核，stride=2\n",
        "- 输出尺寸变为 $1 \\times 14 \\times 14$\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧪 PyTorch 示例代码\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "x = torch.randn(1, 1, 28, 28)\n",
        "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "out = pool(x)\n",
        "print(out.shape)  # torch.Size([1, 1, 14, 14])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结：\n",
        "> 池化层可有效压缩特征图尺寸，提取主要信息并提高模型的平移不变性，是 CNN 中常见的下采样策略。\n"
      ],
      "metadata": {
        "id": "urfz14f_8j4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 模块 5：卷积块堆叠：CNN 的深层结构\n",
        "\n",
        "在实际任务中，一个卷积 + 激活 + 池化层往往不足以提取高阶复杂特征。\n",
        "\n",
        "> 所以现代 CNN 网络通常将多个卷积块堆叠（stack）起来，从而构建出更深、更具表达能力的网络结构。\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 卷积块（Conv Block）的基本构成：\n",
        "```text\n",
        "[Conv → ReLU → Pool] × N\n",
        "```\n",
        "\n",
        "每个卷积块包含：\n",
        "1. 卷积层：提取局部空间特征\n",
        "2. 激活函数：通常使用 ReLU 提高非线性\n",
        "3. 池化层：下采样，缩小尺寸、压缩信息\n",
        "\n",
        "随着层数增加：\n",
        "- 特征图尺寸变小（由池化层控制）\n",
        "- 通道数变多（更强表达能力）\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔍 示例结构（经典 CNN）\n",
        "```text\n",
        "输入图像（1×28×28）\n",
        "↓\n",
        "Conv2D(1→16, kernel=3, padding=1)\n",
        "↓\n",
        "ReLU\n",
        "↓\n",
        "MaxPool2D(kernel=2)\n",
        "↓\n",
        "Conv2D(16→32, kernel=3, padding=1)\n",
        "↓\n",
        "ReLU\n",
        "↓\n",
        "MaxPool2D(kernel=2)\n",
        "↓\n",
        "Flatten → Linear → 输出（10类）\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧪 PyTorch 示例代码\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结：\n",
        "> 将卷积块堆叠起来构建深层结构，是 CNN 学习从局部到全局复杂特征的重要手段，也是现代深度学习网络的通用设计模式。\n"
      ],
      "metadata": {
        "id": "cuwu92fB8v7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 模块 6：CNN vs MLP 的参数数量对比\n",
        "\n",
        "CNN 与 MLP 的主要结构差异在于：\n",
        "- MLP 是**全连接**：每个输入连接到每个神经元，参数量随输入维度线性增长\n",
        "- CNN 是**局部连接 + 参数共享**：每个神经元只连接部分输入，多个位置共用同一卷积核\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 举例对比：输入为 $28 \\times 28 = 784$ 的图像\n",
        "\n",
        "##### 1️⃣ 使用 MLP：\n",
        "```text\n",
        "输入层：784 → 隐藏层：128 → 输出层：10\n",
        "```\n",
        "参数量估算：\n",
        "- 第一层参数：$784 \\times 128 = 100,352$\n",
        "- 第二层参数：$128 \\times 10 = 1,280$\n",
        "- 总计：$\\approx 101,632$ 个参数（还未算 bias）\n",
        "\n",
        "##### 2️⃣ 使用 CNN：\n",
        "```text\n",
        "Conv2D(1→16, kernel=3×3, padding=1)\n",
        "Conv2D(16→32, kernel=3×3, padding=1)\n",
        "```\n",
        "参数量估算：\n",
        "- 第一层卷积核：$1 \\times 3 \\times 3 \\times 16 = 144$\n",
        "- 第二层卷积核：$16 \\times 3 \\times 3 \\times 32 = 4,608$\n",
        "- 总计：$\\approx 4,752$ 个参数（远少于 MLP）\n",
        "\n",
        "---\n",
        "\n",
        "#### 📌 结论对比\n",
        "| 特性               | MLP                           | CNN                             |\n",
        "|--------------------|-------------------------------|----------------------------------|\n",
        "| 连接方式           | 全连接（Dense）               | 局部连接 + 参数共享             |\n",
        "| 参数数量           | 较多（与输入尺寸强相关）     | 较少（与卷积核尺寸有关）        |\n",
        "| 特征感知方式       | 全局                          | 局部到全局层层提取               |\n",
        "| 适合任务           | 表格型、非结构化数据          | 图像、语音、空间相关数据         |\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结一句话：\n",
        "> CNN 利用局部感受野和权重共享机制显著减少参数，在图像类任务中比 MLP 更高效、泛化能力更强。"
      ],
      "metadata": {
        "id": "bMB9tgf086EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 模块 7：CNN 训练流程总结\n",
        "\n",
        "CNN 的训练流程本质与 MLP 类似，都是通过反向传播算法最小化损失函数。但在结构与张量维度上需要特别注意。\n",
        "\n",
        "---\n",
        "\n",
        "#### ✅ 标准训练流程 5 步：\n",
        "1. **数据加载**：使用 `DataLoader` 分 batch 输入\n",
        "2. **前向传播**：图像输入 → 卷积层 → ReLU → 池化 → 全连接层 → 输出 logits\n",
        "3. **计算损失**：常用 `nn.CrossEntropyLoss`（内部已包含 softmax）\n",
        "4. **反向传播**：`loss.backward()` 自动计算梯度\n",
        "5. **参数更新**：`optimizer.step()` 用如 SGD、Adam 等更新参数\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧪 PyTorch 示例代码（训练 1 个 epoch）\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 数据准备\n",
        "transform = transforms.ToTensor()\n",
        "train_set = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "\n",
        "# 模型、损失、优化器\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 训练 1 epoch\n",
        "model.train()\n",
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()       # 清除旧梯度\n",
        "    output = model(data)        # 前向传播\n",
        "    loss = criterion(output, target)  # 计算损失\n",
        "    loss.backward()             # 反向传播\n",
        "    optimizer.step()            # 更新参数\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "        print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔁 常见训练细节：\n",
        "- **多 epoch 训练**：遍历训练集多轮提升性能\n",
        "- **学习率调度器**：`torch.optim.lr_scheduler` 自动调整学习率\n",
        "- **验证集划分**：训练过程中监控验证准确率\n",
        "- **早停（Early Stopping）**：避免过拟合\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结：\n",
        "> CNN 的训练流程基于反向传播和优化器更新，但需要更关注张量维度变化、batch size 与 GPU 显存的配合。掌握标准流程是训练任何深度模型的基础。\n"
      ],
      "metadata": {
        "id": "9xBm98dC9wBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# 🔧 数据预处理\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1000)\n",
        "\n",
        "# 🧠 CNN 模型定义\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # 输出: 16×28×28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # 输出: 16×14×14\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # 输出: 32×14×14\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)                              # 输出: 32×7×7\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32*7*7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ⚙️ 训练流程\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, loader):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        pred = model(data)\n",
        "        loss = loss_fn(pred, target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# 🚀 开始训练\n",
        "for epoch in range(1, 4):\n",
        "    print(f\"\\nEpoch {epoch}\")\n",
        "    train(model, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hgquzI6-NkC",
        "outputId": "69363ec7-5749-4df2-c813-dd2ded3c46f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.4MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 198kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.71MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "Batch 0, Loss: 2.3137\n",
            "Batch 100, Loss: 0.5988\n",
            "Batch 200, Loss: 0.5799\n",
            "Batch 300, Loss: 0.4948\n",
            "Batch 400, Loss: 0.5685\n",
            "Batch 500, Loss: 0.5225\n",
            "Batch 600, Loss: 0.3092\n",
            "Batch 700, Loss: 0.2980\n",
            "Batch 800, Loss: 0.3416\n",
            "Batch 900, Loss: 0.3837\n",
            "\n",
            "Epoch 2\n",
            "Batch 0, Loss: 0.2374\n",
            "Batch 100, Loss: 0.1795\n",
            "Batch 200, Loss: 0.3551\n",
            "Batch 300, Loss: 0.2107\n",
            "Batch 400, Loss: 0.2551\n",
            "Batch 500, Loss: 0.3610\n",
            "Batch 600, Loss: 0.3777\n",
            "Batch 700, Loss: 0.2024\n",
            "Batch 800, Loss: 0.2945\n",
            "Batch 900, Loss: 0.4227\n",
            "\n",
            "Epoch 3\n",
            "Batch 0, Loss: 0.2166\n",
            "Batch 100, Loss: 0.3094\n",
            "Batch 200, Loss: 0.2285\n",
            "Batch 300, Loss: 0.3178\n",
            "Batch 400, Loss: 0.2811\n",
            "Batch 500, Loss: 0.4597\n",
            "Batch 600, Loss: 0.2894\n",
            "Batch 700, Loss: 0.2803\n",
            "Batch 800, Loss: 0.3491\n",
            "Batch 900, Loss: 0.1946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 模块 8：CNN 应用举例\n",
        "\n",
        "卷积神经网络（CNN）作为图像任务的基础模型结构，广泛应用于多个领域，从简单分类到高精度感知任务。\n",
        "\n",
        "---\n",
        "\n",
        "#### 📌 图像相关任务\n",
        "\n",
        "| 应用类型       | 描述 |\n",
        "|----------------|------|\n",
        "| 图像分类       | 输入图像 → 输出标签（如猫/狗）\n",
        "| 目标检测       | 检测图像中多个物体的位置与类别（如 YOLO, Faster R-CNN）\n",
        "| 图像分割       | 像素级分类（如分清每个像素是背景还是目标）\n",
        "| 图像生成       | 如 GAN（生成对抗网络）用于生成新图像\n",
        "| 图像风格迁移   | 把图像 A 的内容用图像 B 的风格表现出来\n",
        "\n",
        "---\n",
        "\n",
        "#### ⚕️ 医学图像领域\n",
        "- CT、MRI、X-ray 图像中的病灶检测（如肺结节、脑肿瘤）\n",
        "- 病理切片分析、组织区域分割（如 U-Net 应用）\n",
        "\n",
        "---\n",
        "\n",
        "#### 🌍 工业与环境监测\n",
        "- 卫星图像识别（如建筑、道路、植被）\n",
        "- 工业瑕疵检测（印刷缺陷、金属裂纹）\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 知名网络代表\n",
        "| 网络名      | 说明 |\n",
        "|-------------|------|\n",
        "| LeNet-5     | 最早成功应用于手写数字识别（MNIST）\n",
        "| AlexNet     | 2012 ImageNet 冠军，引爆深度学习浪潮\n",
        "| VGGNet      | 使用大量 3×3 卷积核堆叠构建深层网络\n",
        "| ResNet      | 引入残差连接（skip connection）解决深层网络退化问题\n",
        "| U-Net       | 用于医学图像分割的编码-解码结构\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 总结：\n",
        "> CNN 的强大空间建模能力和高效结构设计，使其在图像识别、感知、生成、医疗、工业等领域均展现出广泛价值，是深度视觉系统不可或缺的核心模块。\n"
      ],
      "metadata": {
        "id": "mn-6mlZu96du"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnN8j5d66da2"
      },
      "outputs": [],
      "source": []
    }
  ]
}