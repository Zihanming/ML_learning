{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ğŸ”— MLPï¼ˆMulti-Layer Perceptron å¤šå±‚æ„ŸçŸ¥æœºï¼‰ç®€ä»‹\n",
    "\n",
    "å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰æ˜¯æœ€åŸºæœ¬çš„å‰é¦ˆç¥ç»ç½‘ç»œç»“æ„ï¼Œæ˜¯ç°ä»£ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ çš„åŸºç¡€ã€‚å®ƒé€šè¿‡å¤šä¸ªçº¿æ€§å±‚å’Œéçº¿æ€§æ¿€æ´»å‡½æ•°çš„ç»„åˆï¼Œèƒ½å¤Ÿå¯¹è¾“å…¥æ•°æ®å»ºæ¨¡å‡ºå¤æ‚çš„éçº¿æ€§å…³ç³»ã€‚\n",
    "\n",
    "MLP é€šå¸¸ç”¨äºï¼š\n",
    "- åˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚æ‰‹å†™æ•°å­—è¯†åˆ«ã€å®¢æˆ·æµå¤±é¢„æµ‹ï¼‰\n",
    "- å›å½’ä»»åŠ¡ï¼ˆå¦‚æˆ¿ä»·é¢„æµ‹ï¼‰\n",
    "- è¡¨æ ¼å‹ç»“æ„åŒ–æ•°æ®ï¼ˆéå›¾åƒã€éåºåˆ—ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ åŸºæœ¬ç»“æ„\n",
    "\n",
    "ä¸€ä¸ªå…¸å‹çš„ MLP åŒ…æ‹¬ï¼š\n",
    "\n",
    "- **è¾“å…¥å±‚**ï¼šæ¥æ”¶åŸå§‹ç‰¹å¾å‘é‡\n",
    "- **1 ä¸ªæˆ–å¤šä¸ªéšè—å±‚**ï¼šæå–ç‰¹å¾ã€å»ºæ¨¡å¤æ‚æ¨¡å¼\n",
    "- **è¾“å‡ºå±‚**ï¼šç»™å‡ºæœ€ç»ˆçš„é¢„æµ‹ç»“æœï¼ˆå¦‚åˆ†ç±»æ¦‚ç‡ï¼‰\n",
    "\n",
    "æ¯ä¸€å±‚éƒ½æ‰§è¡Œï¼š\n",
    "$$\n",
    "z = W Â· x + b\n",
    "$$\n",
    "\n",
    "$$\n",
    "a = activation(z)\n",
    "$$\n",
    "\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- `W`: æƒé‡çŸ©é˜µ\n",
    "- `b`: åç½®å‘é‡\n",
    "- `activation()`: æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUã€Sigmoidï¼‰(å¯ä»¥å‚è€ƒ basic/model_building_blocks/Activation_function.ipynbï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  MLP å¼•å…¥çš„æ–°æ¦‚å¿µ\n",
    "\n",
    "| æ¦‚å¿µ             | è§£é‡Š |\n",
    "|------------------|------|\n",
    "| **ç¥ç»å…ƒ (Neuron)**       | æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒçš„è®¡ç®—å•å…ƒï¼Œæ‰§è¡Œ $z = w^\\top x + b$ |\n",
    "| **æ¿€æ´»å‡½æ•° (Activation)** | ç»™ç½‘ç»œå¢åŠ éçº¿æ€§èƒ½åŠ›ã€‚å¸¸ç”¨ï¼šReLUã€Sigmoidã€Tanh |\n",
    "| **éšè—å±‚ (Hidden Layer)** | è¾“å…¥å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´çš„ä¸­é—´å±‚ï¼Œç”¨äºæå–ç‰¹å¾ |\n",
    "| **å‰å‘ä¼ æ’­ (Forward Propagation)** | ä»è¾“å…¥ä¾æ¬¡è®¡ç®—æ¯å±‚è¾“å‡ºç›´åˆ°æœ€ç»ˆç»“æœ |\n",
    "| **åå‘ä¼ æ’­ (Backpropagation)**     | åˆ©ç”¨æŸå¤±å‡½æ•°è®¡ç®—æ¢¯åº¦ï¼Œæ›´æ–°ç½‘ç»œæƒé‡ |\n",
    "| **ä¼˜åŒ–å™¨ (Optimizer)**   | æ§åˆ¶å‚æ•°æ›´æ–°æ–¹å¼ï¼Œå¦‚ SGDã€Adam |\n",
    "| **æŸå¤±å‡½æ•° (Loss Function)** | è¡¡é‡é¢„æµ‹ä¸çœŸå®æ ‡ç­¾çš„å·®å¼‚ï¼ŒæŒ‡å¯¼æ¨¡å‹å­¦ä¹  |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” MLP ä¸é€»è¾‘å›å½’çš„å…³ç³»\n",
    "\n",
    "- é€»è¾‘å›å½’ = æ²¡æœ‰éšè—å±‚çš„ MLP\n",
    "- MLP = å¤šå±‚éçº¿æ€§ç»„åˆçš„é€»è¾‘å›å½’\n",
    "- é€»è¾‘å›å½’åªèƒ½å­¦ä¹ çº¿æ€§è¾¹ç•Œï¼Œè€Œ MLP å¯ä»¥å­¦ä¹ ä»»æ„å¤æ‚è¾¹ç•Œï¼ˆç”±å±‚æ•°å’Œæ¿€æ´»å‡½æ•°å†³å®šï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© åº”ç”¨åœºæ™¯ç¤ºä¾‹\n",
    "\n",
    "- é“¶è¡Œå®¢æˆ·æ˜¯å¦ä¼šè´­ä¹°ç†è´¢äº§å“ï¼ˆåˆ†ç±»ï¼‰\n",
    "- é¢„æµ‹è‚¡ç¥¨ä»·æ ¼ï¼ˆå›å½’ï¼‰\n",
    "- ç¥ç»ç½‘ç»œä¸­æœ€å¸¸ç”¨çš„åŸºç¡€ç»“æ„ï¼ˆNLPã€CVå‰èº«ï¼‰\n",
    "\n"
   ],
   "metadata": {
    "id": "XYNqkZhTIOg4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ğŸ”— å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼šç½‘ç»œç»“æ„ä¸å‰å‘ä¼ æ’­\n",
    "\n",
    "## ğŸ§¬ 1. ç¥ç»å…ƒç»“æ„ï¼šçº¿æ€§å˜æ¢ + æ¿€æ´»å‡½æ•°\n",
    "\n",
    "æ¯ä¸ªç¥ç»å…ƒï¼ˆNeuronï¼‰çš„æ ¸å¿ƒæ“ä½œå¯ä»¥è¡¨ç¤ºä¸ºï¼š\n",
    "\n",
    "$$\n",
    "z = \\sum_{i=1}^{n} w_i x_i + b = \\mathbf{w}^\\top \\mathbf{x} + b\n",
    "$$\n",
    "\n",
    "- $\\mathbf{x}$ï¼šè¾“å…¥å‘é‡\n",
    "- $\\mathbf{w}$ï¼šæƒé‡å‘é‡\n",
    "- $b$ï¼šåç½®é¡¹\n",
    "- $z$ï¼šåŠ æƒå’Œ\n",
    "\n",
    "ç„¶åå°† $z$ é€å…¥æ¿€æ´»å‡½æ•° $f(\\cdot)$ å¾—åˆ°è¾“å‡ºï¼š\n",
    "\n",
    "$$\n",
    "a = f(z)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ï¸ 2. ç½‘ç»œå±‚ç»“æ„ï¼šè¾“å…¥å±‚ â†’ éšè—å±‚ â†’ è¾“å‡ºå±‚\n",
    "\n",
    "ä¸€ä¸ªæ ‡å‡†çš„ MLP ç½‘ç»œåŒ…å«ï¼š\n",
    "\n",
    "- **è¾“å…¥å±‚**ï¼šæ¥æ”¶ç‰¹å¾å‘é‡ï¼ˆä¸è®¡ç®—ï¼‰\n",
    "- **ä¸€ä¸ªæˆ–å¤šä¸ªéšè—å±‚**ï¼šæ¯å±‚å«è‹¥å¹²ç¥ç»å…ƒ\n",
    "- **è¾“å‡ºå±‚**ï¼šç”¨äºè¾“å‡ºé¢„æµ‹ç»“æœ\n",
    "\n",
    "ä¾‹å¦‚ä¸€ä¸ªä¸¤å±‚ MLP ç»“æ„å¦‚ä¸‹ï¼š\n",
    "\n",
    "$$\n",
    "\\text{è¾“å…¥å±‚ï¼š} \\quad \\mathbf{x} \\in \\mathbb{R}^n \\\\\n",
    "\\text{éšè—å±‚ï¼š} \\quad \\mathbf{a}^{(1)} = f(W^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)}) \\\\\n",
    "\\text{è¾“å‡ºå±‚ï¼š} \\quad \\hat{\\mathbf{y}} = g(W^{(2)} \\mathbf{a}^{(1)} + \\mathbf{b}^{(2)})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ 3. å‰å‘ä¼ æ’­å…¬å¼ï¼ˆçŸ©é˜µå‘é‡å½¢å¼ï¼‰\n",
    "\n",
    "ä»¥ä¸€ä¸ªéšè—å±‚ä¸ºä¾‹ï¼Œå®Œæ•´å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{z}^{(1)} &= W^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)} \\\\\n",
    "\\mathbf{a}^{(1)} &= f(\\mathbf{z}^{(1)}) \\\\\n",
    "\\mathbf{z}^{(2)} &= W^{(2)} \\mathbf{a}^{(1)} + \\mathbf{b}^{(2)} \\\\\n",
    "\\hat{\\mathbf{y}} &= g(\\mathbf{z}^{(2)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "> è‹¥æœ‰å¤šéšè—å±‚ï¼Œåªéœ€é‡å¤ä¸Šè¿°ç»“æ„ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ 4. è¾“å‡ºå½¢å¼å·®å¼‚ï¼ˆåˆ†ç±» vs å›å½’ï¼‰\n",
    "\n",
    "| ä»»åŠ¡ç±»å‹       | è¾“å‡ºå±‚æ¿€æ´»å‡½æ•° $g(z)$ | å…¸å‹æŸå¤±å‡½æ•°               | è¾“å‡ºèŒƒå›´         |\n",
    "|----------------|------------------------|----------------------------|------------------|\n",
    "| äºŒåˆ†ç±»         | Sigmoid                | Binary Cross-Entropy       | (0, 1) æ¦‚ç‡       |\n",
    "| å¤šåˆ†ç±»         | Softmax                | Categorical Cross-Entropy  | å„ç±»æ¦‚ç‡åˆ†å¸ƒ     |\n",
    "| å›å½’           | Linear (æ’ç­‰æ˜ å°„)      | MSE / MAE                  | å®æ•°åŸŸ            |\n",
    "\n",
    "- **Sigmoid** ç”¨äºå°†è¾“å‡ºå‹ç¼©ä¸ºæ¦‚ç‡\n",
    "- **Softmax** ç”¨äºå¤šç±»åˆ†ç±»ï¼Œè¾“å‡ºä¸ºæ¦‚ç‡åˆ†å¸ƒ\n",
    "- **Linear** ä¿æŒæ•°å€¼è¿ç»­æ€§ï¼Œé€‚ç”¨äºå›å½’ä»»åŠ¡\n"
   ],
   "metadata": {
    "id": "Ku3I0GHEJREF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ğŸ”Œ æ¿€æ´»å‡½æ•°ä¸æƒé‡åˆå§‹åŒ–ï¼ˆActivation & Initializationï¼‰\n",
    "\n",
    "åœ¨å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä¸­ï¼Œæ¿€æ´»å‡½æ•°ç”¨äºä¸ºæ¨¡å‹å¼•å…¥éçº¿æ€§èƒ½åŠ›ï¼Œè€Œæƒé‡åˆå§‹åŒ–åˆ™å½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ä¸ç¨³å®šæ€§ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§® 1. ä¸ºä»€ä¹ˆéœ€è¦æ¿€æ´»å‡½æ•°ï¼Ÿ\n",
    "\n",
    "å¦‚æœæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œå¤šä¸ªçº¿æ€§å±‚å åŠ ä»ç„¶æ˜¯çº¿æ€§çš„ï¼ŒMLP é€€åŒ–ä¸ºçº¿æ€§æ¨¡å‹ï¼š\n",
    "\n",
    "$$\n",
    "f(x) = W_2(W_1 x + b_1) + b_2 = W x + b\n",
    "$$\n",
    "\n",
    "> å› æ­¤æ¿€æ´»å‡½æ•°å¿…é¡»éçº¿æ€§ï¼Œæ‰èƒ½è®© MLP å­¦ä¹ å¤æ‚çš„å‡½æ•°å…³ç³»ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ 2. å¸¸è§æ¿€æ´»å‡½æ•°å¯¹æ¯”\n",
    "\n",
    "| æ¿€æ´»å‡½æ•° | è¡¨è¾¾å¼ | è¾“å‡ºèŒƒå›´ | æ˜¯å¦ä¸­å¿ƒåŒ– | æ˜¯å¦ç¨€ç– | ä¼˜ç‚¹ | ç¼ºç‚¹ |\n",
    "|----------|--------|----------|--------------|------------|------|------|\n",
    "| Sigmoid | $\\frac{1}{1 + e^{-x}}$ | (0, 1) | âŒ | âŒ | å¯å¯¼ã€æ¦‚ç‡è¾“å‡º | æ¢¯åº¦æ¶ˆå¤±ã€è¾“å‡ºéé›¶ä¸­å¿ƒ |\n",
    "| Tanh | $\\tanh(x)$ | (-1, 1) | âœ… | âŒ | è¾“å‡ºé›¶ä¸­å¿ƒï¼Œæ¢¯åº¦å¤§äº sigmoid | æ¢¯åº¦ä»å¯èƒ½æ¶ˆå¤± |\n",
    "| ReLU | $\\max(0, x)$ | [0, âˆ) | âŒ | âœ…ï¼ˆéƒ¨åˆ†è¾“å‡ºä¸º 0ï¼‰ | æ”¶æ•›å¿«ã€è®¡ç®—ç®€å• | Dying ReLU é—®é¢˜ |\n",
    "| Leaky ReLU | $\\max(\\alpha x, x)$ | (-âˆ, âˆ) | âŒ | âœ… | ç¼“è§£ Dying ReLU é—®é¢˜ | Î± éœ€è¦è°ƒå‚ |\n",
    "| GELU / Swish | è‡ªé€‚åº”å¹³æ»‘ | (-âˆ, âˆ) | âœ… | âŒ | æ–°ä¸€ä»£æ¿€æ´»ï¼Œæ•ˆæœå¥½ | è®¡ç®—è¾ƒæ…¢ |\n",
    "\n",
    "å…·ä½“å¯ä»¥å‚è€ƒbasic_conceptä¸­æ¿€æ´»å‡½æ•°éƒ¨åˆ†\n",
    "---\n",
    "\n",
    "## ğŸ”§ 3. ä¸ºä»€ä¹ˆåˆå§‹åŒ–å¾ˆé‡è¦ï¼Ÿ\n",
    "\n",
    "- ä¸æ°å½“çš„åˆå§‹åŒ–å¯èƒ½å¯¼è‡´ï¼š\n",
    "  - æ¢¯åº¦æ¶ˆå¤±æˆ–çˆ†ç‚¸ï¼ˆè®­ç»ƒä¸æ”¶æ•›ï¼‰\n",
    "  - æ‰€æœ‰ç¥ç»å…ƒè¡Œä¸ºä¸€è‡´ï¼ˆæ— å­¦ä¹ ï¼‰\n",
    "\n",
    "åˆå§‹åŒ–ç›®æ ‡ï¼š\n",
    "> ä¿æŒæ¯å±‚è¾“å‡ºçš„æ–¹å·®ç¨³å®šï¼Œé¿å…ä¿¡å·åœ¨ä¼ æ’­è¿‡ç¨‹ä¸­å˜å¤§æˆ–å˜å°\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ 4. å¸¸è§åˆå§‹åŒ–æ–¹æ³•\n",
    "\n",
    "| åˆå§‹åŒ–æ–¹æ³• | åŸç† | æ¨èæ¿€æ´» | æ•°å­¦è¡¨è¾¾ |\n",
    "|------------|------|----------|-----------|\n",
    "| å¸¸è§„å‡åŒ€åˆ†å¸ƒ | å›ºå®šèŒƒå›´éšæœºå€¼ | æ—©æœŸæ–¹æ³• | $U(-0.1, 0.1)$ |\n",
    "| Xavier åˆå§‹åŒ– | ä¿æŒå‰åæ–¹å·®ä¸€è‡´ | Sigmoid / Tanh | $\\mathcal{N}(0, \\frac{1}{n_{\\text{in}}})$ |\n",
    "| He åˆå§‹åŒ– | è€ƒè™‘ ReLU æˆªæ–­ | ReLU ç³»åˆ— | $\\mathcal{N}(0, \\frac{2}{n_{\\text{in}}})$ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ å°ç»“\n",
    "\n",
    "- æ¿€æ´»å‡½æ•°å†³å®šäº†æ¨¡å‹çš„éçº¿æ€§èƒ½åŠ›ï¼Œæ˜¯æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒéƒ¨åˆ†ä¹‹ä¸€\n",
    "- å¸¸ç”¨ ReLU ä½œä¸ºé»˜è®¤æ¿€æ´»å‡½æ•°ï¼Œä¹Ÿå¯å°è¯• Swish/GELU ç­‰\n",
    "- æƒé‡åˆå§‹åŒ–éœ€ä¸æ¿€æ´»å‡½æ•°åŒ¹é…ï¼Œå¦‚ä½¿ç”¨ ReLU å»ºè®®ç”¨ He åˆå§‹åŒ–\n",
    "\n"
   ],
   "metadata": {
    "id": "G9q1bTgOKPzn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y3gM6n80IKbj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# æ•°æ®é¢„å¤„ç†ï¼šè½¬æ¢ä¸ºTensor & æ ‡å‡†åŒ–\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # è½¬æ¢ä¸ºå¼ é‡ (0~1)\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST å‡å€¼ & æ ‡å‡†å·®\n",
    "])\n",
    "\n",
    "# ä¸‹è½½è®­ç»ƒå’Œæµ‹è¯•é›†\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# æ•°æ®åŠ è½½å™¨\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4k0svYRTOUCX",
    "outputId": "ff1bc954-f489-49cf-b8bb-d41e4f6b4ff9"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 56.4MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 1.65MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 13.9MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 4.88MB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),             # 28x28 -> 784\n",
    "            nn.Linear(784, 128),      # è¾“å…¥å±‚ â†’ éšè—å±‚1\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),       # éšè—å±‚1 â†’ éšè—å±‚2\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)         # éšè—å±‚2 â†’ è¾“å‡ºå±‚ï¼ˆ10ç±»ï¼‰\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ],
   "metadata": {
    "id": "T4-F1bSCOWLh"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()              # è‡ªåŠ¨åŠ  softmax + one-hot loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ],
   "metadata": {
    "id": "hr4mkPZEOYZM"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # åå‘ä¼ æ’­ + æ›´æ–°å‚æ•°\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loader.dataset)}]  Loss: {loss.item():.4f}\")\n"
   ],
   "metadata": {
    "id": "ePPvD679OaUk"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ],
   "metadata": {
    "id": "o8U9Slv8Obwm"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(model, train_loader, optimizer, criterion, epoch)\n",
    "    test(model, test_loader)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICMRAaLUOmgz",
    "outputId": "8d462248-9266-4253-f7b4-8fb7f0a22951"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000]  Loss: 2.2964\n",
      "Train Epoch: 1 [6400/60000]  Loss: 0.4901\n",
      "Train Epoch: 1 [12800/60000]  Loss: 0.3854\n",
      "Train Epoch: 1 [19200/60000]  Loss: 0.2871\n",
      "Train Epoch: 1 [25600/60000]  Loss: 0.2668\n",
      "Train Epoch: 1 [32000/60000]  Loss: 0.2352\n",
      "Train Epoch: 1 [38400/60000]  Loss: 0.1647\n",
      "Train Epoch: 1 [44800/60000]  Loss: 0.0816\n",
      "Train Epoch: 1 [51200/60000]  Loss: 0.1236\n",
      "Train Epoch: 1 [57600/60000]  Loss: 0.1558\n",
      "Test Accuracy: 95.40%\n",
      "Train Epoch: 2 [0/60000]  Loss: 0.1232\n",
      "Train Epoch: 2 [6400/60000]  Loss: 0.1517\n",
      "Train Epoch: 2 [12800/60000]  Loss: 0.1374\n",
      "Train Epoch: 2 [19200/60000]  Loss: 0.2623\n",
      "Train Epoch: 2 [25600/60000]  Loss: 0.0645\n",
      "Train Epoch: 2 [32000/60000]  Loss: 0.0887\n",
      "Train Epoch: 2 [38400/60000]  Loss: 0.3113\n"
     ]
    }
   ]
  }
 ]
}
